tags: #notes #fleeting
creation date: [[2022-10-17 Monday]] 11:00:41
description:: finishing series, Growth Rates of Functions

last class was the exam
there were like 5 questions i think i did like fine
why isnt the zoom starting

what did he say at the start
whatever

more summations now i guess
and then computational complexity after

##### Differentiating Series
$\sum^{\infty}_{k=0} kx^{k-1}$ = $\frac 1 {(1-x)^2}$ for $|x| < 1$.
proof: lm,ao im not writing that out

##### Harmonic Series
$H_n = \sum^n_{i=1} \frac 1 i < 1 + lnn$
![[Pasted image 20221017112041.png]]
graph shows $f(x) = \frac 1 x$ line starting at 1
area under this curve is $\int^n_1 \frac 1 x dx$
proof
$1 + \int^n_1 \frac 1 x dx = 1 + lnx|^n_1 = 1 + ln n - ln 1 = 1 + lnn$

##### Telescoping Series
For any sequence $a_0, a_1,..., 1_n$, $\sum^n_{k=1} (a_k - a_{k-1}) = a_n - a_0$
see notes for a good example that im not gonna write down

end of sequences and series


## Growth Rates of Functions
We need a measure to compare the efficiency of algorithms (for a given criterion, time, space, energy, etc). We measure in flops, ops, bytes, Joules, etc. The final functions are increasing (non-decreasing) with problem size.
We need to get a "feel" of how fast these functions grow as their variables grow.

ex.
Alg A is linear
- twice the size, takes twice as long
Alg B is exponential
- twice the size, way longer
however theres a point where Alg B is more efficient than Alg A, under some $n_0$

We say that Alg A is asymptotically faster than Alg B
![[ED6F9522-9A3E-466F-AB20-3C10F7C1F485.jpeg]]

##### Big-O
Big-O is used to **compare growth rates of two increasing functions**
$f(x)$ and $g(x)$

say $f(x) = O(g(x))$ or $f(x) \in O(g(x))$
iff $\exists c, k : f(x) \leq c * g(x) \forall x \geq k$
implies the growth rate of $f(x)$ is **less than or equal to** the growth rate of $g$.

ex. $f(x) = x, g(x) = x^2$
grows faster: $g$
is faster: $f$

end of class